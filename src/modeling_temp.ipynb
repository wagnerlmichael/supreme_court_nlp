{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import subprocess as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "base_path = sp.getoutput('git rev-parse --show-toplevel')\n",
    "os.chdir(base_path)\n",
    "\n",
    "from src import embed, pred_models, model_helpers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_22856\\2014623051.py:4: DtypeWarning: Columns (17,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(os.path.join(base_path, data_dir, file))\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = 'data'\n",
    "file = 'utterances_clean2014-2018.csv'\n",
    "df_raw = pd.read_csv(os.path.join(base_path, data_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>win_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We will hear argument first this morning in Ca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We'll hear argument next in Case 12-1497, Kell...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We will hear argument next in Case 131010, M&amp;G...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We'll hear argument first this morning in Case...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We will hear argument first this morning in Ca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  win_side\n",
       "0  We will hear argument first this morning in Ca...       1.0\n",
       "1  We'll hear argument next in Case 12-1497, Kell...       1.0\n",
       "2  We will hear argument next in Case 131010, M&G...       1.0\n",
       "3  We'll hear argument first this morning in Case...       1.0\n",
       "4  We will hear argument first this morning in Ca...       1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTION 1\n",
    "# In the context of pandas' groupby and agg methods, \n",
    "# 'first' is an aggregation function that returns the \n",
    "# first non-null value in each group of values.\n",
    "df = (df_raw.groupby('case_id')\n",
    "        .agg({'text': ' '.join, 'win_side': 'first'})\n",
    "        .reset_index()\n",
    "        .drop(['case_id'], axis=1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>win_side</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We'll hear argument next in Case No. 13-553, t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014_13-553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you, Mr. Chief Justice, and may it pleas...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014_13-553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, is said that -- it said that in -- in (b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014_13-553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right. I -- but I think--</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014_13-553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Another tax that discriminates is all it says,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014_13-553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  win_side      case_id\n",
       "0  We'll hear argument next in Case No. 13-553, t...       1.0  2014_13-553\n",
       "1  Thank you, Mr. Chief Justice, and may it pleas...       1.0  2014_13-553\n",
       "2  Well, is said that -- it said that in -- in (b...       1.0  2014_13-553\n",
       "3                          Right. I -- but I think--       1.0  2014_13-553\n",
       "4  Another tax that discriminates is all it says,...       1.0  2014_13-553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTION 2\n",
    "df = df_raw[['text', 'win_side', 'case_id']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_22856\\1009847024.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=['win_side'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# TO DISCUSS\n",
    "df.dropna(subset=['win_side'], inplace=True)\n",
    "df = df[df.win_side != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words\n",
    "vocab = embed.get_vocab(train_df, min_freq=10)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, validation, and testing dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_df = train_df[['text', 'win_side']] # Remove case ID for training\n",
    "train_valid_data = list(train_df.values)\n",
    "num_train = int(len(train_valid_data) * 0.95)\n",
    "num_valid = len(train_valid_data) - num_train\n",
    "train_data, valid_data = random_split(\n",
    "    train_valid_data, [num_train, num_valid])\n",
    "test_df_to_dataloader = test_df[['text', 'win_side']] # Remove case ID for utterance prediction, but will concatenate case probs together\n",
    "test_data, _ = random_split(list(test_df_to_dataloader.values), [len(test_df), 0])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=lambda batch: embed.collate_into_bow(batch, vocab)) # pass vocab to collate function\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=lambda batch: embed.collate_into_bow(batch, vocab))\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, \n",
    "                             collate_fn=lambda batch: embed.collate_into_bow(batch, vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW NN Classifier\n",
    "hidden_dim = 300\n",
    "model = pred_models.BoWNNClassifier(vocab_size=vocab_size, hidden_dim=hidden_dim, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\miniconda3\\envs\\final_project_capp30255\\lib\\site-packages\\torch\\_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 200 the loss is 0.614.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m      9\u001b[0m     epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m     model_helpers\u001b[39m.\u001b[39;49mtrain_an_epoch(model, train_dataloader, optimizer, loss_function)\n\u001b[0;32m     11\u001b[0m     accuracy \u001b[39m=\u001b[39m model_helpers\u001b[39m.\u001b[39mget_accuracy(model, valid_dataloader, \u001b[39m0.5\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_acc:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Harris\\2nd_year\\3rd_quarter\\Machine_Learning_(NLP)\\final_project\\supreme_court_nlp\\src\\model_helpers.py:9\u001b[0m, in \u001b[0;36mtrain_an_epoch\u001b[1;34m(model, dataloader, optimizer, loss_function)\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m log_interval \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m idx, (label, text) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     10\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m     log_probs \u001b[39m=\u001b[39m model(text)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\matth\\miniconda3\\envs\\final_project_capp30255\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\matth\\miniconda3\\envs\\final_project_capp30255\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\matth\\miniconda3\\envs\\final_project_capp30255\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      9\u001b[0m test_df_to_dataloader \u001b[39m=\u001b[39m test_df[[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwin_side\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m# Remove case ID for utterance prediction, but will concatenate case probs together\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_data, _ \u001b[39m=\u001b[39m random_split(\u001b[39mlist\u001b[39m(test_df_to_dataloader\u001b[39m.\u001b[39mvalues), [\u001b[39mlen\u001b[39m(test_df), \u001b[39m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(train_data, batch_size\u001b[39m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     13\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m---> 14\u001b[0m                               collate_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m batch: embed\u001b[39m.\u001b[39;49mcollate_into_bow(batch, vocab)) \u001b[39m# pass vocab to collate function\u001b[39;00m\n\u001b[0;32m     15\u001b[0m valid_dataloader \u001b[39m=\u001b[39m DataLoader(valid_data, batch_size\u001b[39m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     16\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[0;32m     17\u001b[0m                               collate_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m batch: embed\u001b[39m.\u001b[39mcollate_into_bow(batch, vocab))\n\u001b[0;32m     18\u001b[0m test_dataloader \u001b[39m=\u001b[39m DataLoader(test_data, batch_size\u001b[39m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     19\u001b[0m                              shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[0;32m     20\u001b[0m                              collate_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m batch: embed\u001b[39m.\u001b[39mcollate_into_bow(batch, vocab))\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Harris\\2nd_year\\3rd_quarter\\Machine_Learning_(NLP)\\final_project\\supreme_court_nlp\\src\\embed.py:50\u001b[0m, in \u001b[0;36mcollate_into_bow\u001b[1;34m(batch, vocab)\u001b[0m\n\u001b[0;32m     48\u001b[0m     labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((labels, torch\u001b[39m.\u001b[39mtensor([label])), \u001b[39m0\u001b[39m)\n\u001b[0;32m     49\u001b[0m     row_tokens \u001b[39m=\u001b[39m [vocab[t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokenizer(token)]\n\u001b[1;32m---> 50\u001b[0m     cum_freq \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbincount(torch\u001b[39m.\u001b[39;49mtensor(row_tokens), minlength\u001b[39m=\u001b[39mvocab_size)\u001b[39m.\u001b[39mresize(\u001b[39m1\u001b[39m, vocab_size)\n\u001b[0;32m     51\u001b[0m     tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((tokens, cum_freq \u001b[39m/\u001b[39m (torch\u001b[39m.\u001b[39msum(cum_freq) \u001b[39m+\u001b[39m \u001b[39m1e-7\u001b[39m)), \u001b[39m0\u001b[39m) \n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m labels, tokens\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "loss_function = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    model_helpers.train_an_epoch(model, train_dataloader, optimizer, loss_function)\n",
    "    accuracy = model_helpers.get_accuracy(model, valid_dataloader, 0.5)\n",
    "    if accuracy > best_acc:\n",
    "        best_model = type(model)(model.vocab_size, model.hidden_dim, model.output_dim) # get a new instance\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "    accuracies.append(accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "    \n",
    "plt.plot(range(1, EPOCHS+1), accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Best number of epochs following validation results\n",
    "# EPOCHS = torch.argmax(torch.tensor(accuracies))\n",
    "# EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 200 the loss is 0.092.\n",
      "At iteration 400 the loss is 0.091.\n",
      "At iteration 600 the loss is 0.108.\n",
      "At iteration 800 the loss is 0.136.\n",
      "At iteration 200 the loss is 0.211.\n",
      "At iteration 400 the loss is 0.136.\n",
      "At iteration 600 the loss is 0.123.\n",
      "At iteration 800 the loss is 0.140.\n",
      "At iteration 200 the loss is 0.120.\n",
      "At iteration 400 the loss is 0.112.\n",
      "At iteration 600 the loss is 0.106.\n",
      "At iteration 800 the loss is 0.163.\n",
      "Test accuracy is 0.732.\n"
     ]
    }
   ],
   "source": [
    "# # Retrain model at best number of epochs and calculate test accuracy\n",
    "# model = pred_models.BoWNNClassifier(vocab_size=vocab_size, hidden_dim=hidden_dim, output_dim=1)\n",
    "# loss_function = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     model_helpers.train_an_epoch(model, train_dataloader, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.732.\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model_helpers.get_accuracy(best_model, test_dataloader, 0.5)\n",
    "print(f'Test accuracy is {test_accuracy:.3f}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
